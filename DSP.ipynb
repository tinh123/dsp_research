{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSP - Digital Signal Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Signal\n",
    "- Signal is anything that serves to indicate, warn, direct, command, or the like, as a light, a gesture, an act, etc.\n",
    "- Signal is anything agreed upon or understood as the occasion for concerted action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of electronic signal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analog signal \n",
    "An analog signal is one type of <strong>continuous time-varying</strong> signals, and these are classified into composite and simple signals. A simple type of analog signal is nothing but a sine wave, and that can’t be decomposed, whereas a composite type analog signal can be decomposed into numerous sine waves. \n",
    "- An analog signal can be defined by using amplitude, time period otherwise frequency, & phase. \n",
    "    - Amplitude streaks the highest height of the signal, \n",
    "    - Frequency streaks the rate at which an analog signal is varying\n",
    "    - Phase streaks the signal position with respect to time nothing.\n",
    "    \\begin{equation}\n",
    "    \\mathbf{a = A.cos(\\omega t+\\phi)}\n",
    "    \\end{equation}\n",
    "    ![analog_example](images/4.1-analog-signal.jpg)\n",
    "- An analog signal is not resistant toward the noise, therefore; it faces distortion as well as reduces the transmission quality. The analog signal value range cannot be fixed.\n",
    "![analog](images/analogSignal.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digital signal\n",
    "- A digital signal carries the data in the form of **binary** because it signifies in the bits. \n",
    "- These signals can be decomposed into sine waves which are termed as harmonics. Every digital signal has amplitude, frequency, & phase like the analog signal. This signal can be defined by bit interval as well as bit rate. Here, bit interval in nothing but the required time for transmitting an only bit, whereas the bit rate is bit interval frequency.\n",
    "![digital](images/digitalSiagnal.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is dsp?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Digital Signal Processors (DSP) take real-world signals like voice, audio, video, temperature, pressure, or position that have been digitized and then mathematically manipulate them. \n",
    "- A DSP is designed for performing mathematical functions like \"add\", \"subtract\", \"multiply\" and \"divide\" very quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentals of Audio Signals and Systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sound\n",
    "- Sound is a vibration that propagates as an __acoustic wave__, through a transmission medium such as a gas, liquid or solid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a sound\n",
    "**Time domain** consists of amplitude that varies with time. This is commonly referred to as filter-out overall reading <br>\n",
    " **Frequency domain** is the domain where amplitudes are shown as series of sine and cosin waves. These waves have a magnitude and a phase, which vary with frequency.<br>\n",
    "\n",
    "![Fourier_transform](images/Fourier-transform.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring the sound\n",
    "The sound pressure level (SPL) expressed in decibels (dB) uses the definition that pressure 0 is 20 μPa (20 μPa = 0.00002 Pa), and pressure 1 is the effective pressure (root-mean-square or RMS) measured with a microphone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hearing threshold is the sound level below which a person’s ear is unable to detect any sound. For adults, 0 dB is the reference level.\n",
    "- A threshold shift is an increase in the hearing threshold for a particular sound frequency. It means that the hearing sensitivity decreases and that it becomes harder for the listener to detect soft sounds. Threshold shifts can be temporary or permanent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sound wave—the pressure disturbance of alternating high and low pressure—progresses through the air at a rate referred to as the speed of sound."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wavelength, Frequency, and Spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sound_wave](images/cycles.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The amount of time required for one oscillation is known as the period of the vibration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wavelength\n",
    "Wavelength is the distance traveled by the sound wave in the time of one period of the oscillation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![weigth_length](images/weightlength.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frequency\n",
    "Sound oscillations are commonly expressed as an oscillation rate: how many cycles of the oscillation occur in 1 s [cycles/second]. The oscillation rate is the frequency of the oscillation. It is customary to use the unit hertz (abbreviated Hz) for a cycles/second frequency measurement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spectrum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A graph of the spectrum of a sinusoid(sine wave) looks like a single “frequency line\". Because a pure tone (sinusoidal waveform) has energy only at the frequency of its repetition rate.\n",
    "\n",
    "![spectrum](images/spectrum.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A sound spectrum is a representation of a sound – usually a short sample of a sound – in terms of the amount of vibration at each individual frequency.\n",
    "- We can think of the sound spectrum as a sound recipe: take this amount of that frequency, add this amount of that frequency etc until you have put together the whole, complicated sound.\n",
    "![spectrum](images/crspec.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spectrum is a common transform used to gain information from a person's speech signal. It can be used to separate the **\"excitation signal\"** (which contains the words(sound) and the pitch) and the **transfer function** (which contains the voice quality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Digital audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Digitization refers to two processes performed by a circuit known as an analog-to-digital converter (ADC).\n",
    "- The first process in the ADC is time sampling, which means a rapid and repeated measurement of the instantaneous value of the analog audio signal many times per second. Each individual measurement is a time sample. The rate at which the time sampling occurs is called the sampling rate, expressed in samples per second [Hz].\n",
    "![timesampling](images/timesampling.gif)\n",
    "- The second process in the ADC is quantization, which means representing each waveform sample with an integer value. The precision of the measurement is typically expressed by the number of digital bits used for each sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bit rate - audio quality \n",
    "- Bit rate (bitrate or as a variable R) is the number of bits that are conveyed or processed per unit of time.\n",
    "- The bit rate is quantified using the bits per second unit (symbol: \"bit/s\"), often in conjunction with an SI prefix such as \"kilo\" (1 kbit/s = 1,000 bit/s), \"mega\" (1 Mbit/s = 1,000 kbit/s), \"giga\" (1 Gbit/s = 1,000 Mbit/s) or \"tera\" (1 Tbit/s = 1000 Gbit/s).[2] The non-standard abbreviation \"bps\" is often used to replace the standard symbol \"bit/s\", so that, for example, \"1 Mbps\" is used to mean one million bits per second."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human voice processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Source Filter Model of Speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The components of speech are the **words** and the **voice** .\n",
    "\n",
    "To speak, air is first released over the vocal cords, which expand and contract to give the air column structure. This is the biological concept of words. The words are then passed through the vocal tract where they are shaped, giving them intonation. This shaping of the words is the biological concept of voice.\n",
    "=> So, words is the information known as source, we need a filter to transform to the voice and speech out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source filter model is a model of speech where the spoken word is comprised of a source component originating from the vocal cords which is then shaped by a filter immitating the effect of the vocal tract.\n",
    "![source_filter](images/source_filter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Signal Processing Considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The source filter model can easily be extended to signal processing. The source is simply a signal __x(t)__. This signal is the input to the filter and is called the __excitation signal__ since it excites the vocal tract.\n",
    "\n",
    "The vocal tract is a filter, it is a linear time-invariant system with **impulse response h(t)**. This is sometimes called the **transfer function** of speech since it is what transfers the excitation signal to speech - it adds voice to words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speech is the output y(t) of the source signal x(t) passed through the filter with impulse response h(t). Thus, the output is given by y(t) = x(t) ∗ h(t).\n",
    "![speech_model](images/speech_modeling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Convolution\n",
    "- Convolution is a formal mathematical operation, just as multiplication, addition, and integration. Addition takes two numbers and produces a third number, while **convolution takes two signals and produces a third signal**. \n",
    "- Convolution is used in the mathematics of many fields, such as probability and statistics. In linear systems, convolution is used to **describe the relationship between three signals of interest: the input signal (excitation signal x(t)), the impulse response (transfer function h(t)), and the output signal**.\n",
    "\n",
    "Linear system : http://www.dspguide.com/ch5/7.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Deconvolution\n",
    "- Deconvolution is exactly what it sounds like: the undoing of convolution. This means that instead of mixing two signals like in convolution, we are isolating them.\n",
    "- This is useful for analyzing the characteristics of the input signal and the impulse response when only given the output of the system.\n",
    "![deconvolutions](images/deconvolutions.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Linear Predictive Coding (LPC) in Voice Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Linear Predictive Coding (or \"LPC\") is a method of predicting a sample of a speech signal **based on several previous samples.**\n",
    "- We can use the LPC coefficients to separate a speech signal into two parts: the transfer function h(t) (which contains the vocal quality) and the excitation x(t) (which contains the pitch and the sound)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \\begin{equation} \\hat{s} = \\sum_{k=1}^{p} {a_k}{s[n-k]} \\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The number of samples (p) is referred to as the \"order\" of the LPC. <br>\n",
    "    As p approaches infinity, we should be able to predict the nth sample exactly. However, p is usually on the order of ten to twenty, where it can provide an accurate enough representation with a limited cost of computation.<br> \n",
    "- The weights on the previous samples (ak) are chosen in order to minimize the squared error between the real sample and its predictedvalue.<br>\n",
    "    Thus, we want the error signal e(n), which is sometimes referred to as the LPC residual, to be as small as possible:<br>\n",
    "    # \\begin{equation} e[n] = s[n]- \\hat{s}[n]= s[n]- \\sum_{k=1}^{p} {a_k}{s[n-k]} \\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take the z-transform of the above equation:\n",
    "# \\begin{equation} E(z) = S(z) - \\sum_{k=1}^{p} {a_k}{S(z)z^{-k}} = S(z)[1 - \\sum_{k=1}^{p}{a_k}z^{-k}]  =S(z)A(z) \\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can represent our original speech signal S(z) as the product of the error signal E(z) and the transfer function 1 / A(z):\n",
    "# \\begin{equation}  S(z) = \\frac{E(z)}{A(z)} \\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In speech processing, computing the LPC coefficients of a signal gives us its ak values. <br>\n",
    "\n",
    "- We can get the filter A(z) as described above. A(z) is the transfer function between the original signal s[n] and the excitation component e[n]. <br>\n",
    "    - The transfer function of a speech signal is the part dealing with the voice quality:What distinguishes one person's voice from another. The excitation component of a speech signal is the part dealing with the particular sounds and words that are produced. <br>\n",
    "- In the time domain, the excitation and transfer function are convolved to create the output voice signal. As shown in the figure below, we can put the original signal through the filter to get the excitation component.<br>\n",
    "    - Putting the excitation component through the inverse filter (1 / A(z)) gives us the original signal back.<br>\n",
    "    ![LPC](images/LPC_al.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform voice conversion by **replacing the excitation component** from the given speaker with a new one. Since we are still using the same transfer function A(z), the resulting speech sample will have the same voice quality as the original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Changing Pitch with PSOLA(Pitch-Synchronous Overlap and Add) for Voice Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Pitch period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Voiced sounds as vowels have a periodic structure, ie , their signal form repeats itself after time, and this is called the pitch period TP . Its reciprocal value fP = 1/TP is called the pitch frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There are a number of algorithms for pitch period estimation. The two broad categories of pitch-estimation algorithms are the time-domain and frequency-domain algorithms.\n",
    "- Time-domain algorithms attempt to determine the **pitch directly** from the speech waveform \n",
    "- Frequency domain algorithms use some forms of spectral analysis to determine the **pitch period**.\n",
    "- Pitch changes, pitch scaling, or pitch modification means transposing the pitch without changing the characteristics of the sound. In addition, it is defined as the process of changing the pitch without affecting the speech."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Pitch shifting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The pitch period is responsible for making some sounds to be sharper than others. The number of vibrations produced during a given period determines the pitch period. This vibration rate of a sound is called its frequency, the higher the frequency the higher the pitch. \n",
    "- The aim of pitch shifting algorithms is to create a change in pitch without creating a change in the replay rate. Pitch shifting can be done by performing a time stretch using PSOLA and resampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 PSOLA - Pitch Synchronous Over Lap-Add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PSOLA is a method used to manipulate the pitch of a speech signal to match it to that of the target speaker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- PSOLA is a method based on decomposition of a signal into a series of elementary waveforms in such a way that each waveform represents one of the successive pitch periods of the signal and the sum (overlap-add) of them reconstitutes the signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several types of PSOLA such as Time Domain TD-PSOLA, Frequency Domain PSOLA (FD-PSOLA) and the Linear-Predictive PSOLA (LP-PSOLA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 TD-PSOLA algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TD-PSOLA algorithm was proposed allowing **pitch modification** of a given speech signal **without changing the time duration and visa versa**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Analysis \n",
    "    - The original speech signal is first divided into separate but often overlapping shortterm analysis signals (ST). Short term signals $x_m(n)$ are obtained from the digital speech waveform x(n) by multiplying the signal by a sequence of the pitch-synchronous analysis window $h_m(n)$\n",
    "    ### \\begin{equation} X_m(n) = h_m(t_m-n)x(n) \\end{equation}\n",
    "    where m is an index for the short-time signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. The windows,\n",
    "    - Windowing is the process of taking a small subset of a larger dataset, for processing and analysis. A naive approach, the rectangular window, involves simply truncating the dataset before and after the window, while not modifying the contents of the window at all.\n",
    "    - Windowing is the equivalent of multiplying the signal sample by a windown function of the same length. A window must be applied to the data to minimize signal 'leakage' effects\n",
    "    - There are centered on the successive instants $t_m$ , called pitchmarks. These marks are set at a pitch-synchronous rate on the voiced parts of the signal and at a constant rate on the unvoiced parts. <br>\n",
    "    ref: https://think-engineer.com/blog/dsp/window-functions-and-how-we-use-them-in-dsp , \n",
    "    https://www.slideshare.net/ramagianhendraloka/windowing-signal-processing?from_action=save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. The modification\n",
    "    - Each frame is modified according to the target. The synthesis steps are performed such that these segments are recombined by means of overlap adding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pitch_change](images/pitchchange.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Pitch Shifting by Time Stretching using PSOLA and Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pitch shifting by time stretching and resampling involves simply performing a time stretch as described earlier with the PSOLA and then resampling in order to return sound length to its original value. \n",
    "- Expanding the sound by time stretch then resampling creates a higher pitch, while compressing and resampling creates a deeper pitch.\n",
    "    ![pitchshift](images/PitchShift.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Pitch detection\n",
    "- Pitch determination is essential for many speech processing tasks and applications, this includes the  classification of speech signal into voiced or unvoiced speech regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several types of pitch detection algorithms such as:\n",
    "- Time-domain analysis like Autocorrelation method, AMDF (Average Magnitude Difference Function)\n",
    "- Frequency-domain analysis like Cepstrum, Harmonic product spectrum, Chens heuristic method\n",
    "- Others like Maximum likelihood, Simple inverse filter tracking (SIFT), Neural network approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
